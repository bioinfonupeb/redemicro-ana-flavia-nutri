{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP : Taxonomic assignment\n",
    "#### Taxonomic assignment with Silva 16S\n",
    "\n",
    "Using Silva 16S classifier for Qiime2. List with all [classifiers](https://docs.qiime2.org/2020.6/data-resources/). \n",
    "\n",
    "#### Versions \n",
    "- [Silva 138 99% OTUs full-length sequences](https://data.qiime2.org/2020.6/common/silva-138-99-nb-classifier.qza)\n",
    "- [Silva 138 99% OTUs from 515F/806R region of sequences](https://data.qiime2.org/2020.6/common/silva-138-99-515-806-nb-classifier.qza)\n",
    "- [Greengenes 13_8 99% OTUs full-length sequences](https://data.qiime2.org/2020.6/common/gg-13-8-99-nb-classifier.qza)\n",
    "- [Greengenes 13_8 99% OTUs from 515F/806R region of sequences](https://data.qiime2.org/2020.6/common/gg-13-8-99-515-806-nb-classifier.qza)\n",
    "\n",
    "#### Methods\n",
    "- [qiime feature-classifier](https://docs.qiime2.org/2022.2/plugins/available/feature-classifier/)\n",
    "- [qiime feature-classifier classify-sklearn](https://docs.qiime2.org/2021.8/plugins/available/feature-classifier/classify-sklearn)\n",
    "- [qiime metadata](https://docs.qiime2.org/2022.2/plugins/available/metadata/)\n",
    "- [classify-hybrid-vsearch-sklearn](https://docs.qiime2.org/2022.2/plugins/available/feature-classifier/classify-hybrid-vsearch-sklearn/)\n",
    "- [qiime metadata tabulate](https://docs.qiime2.org/2022.2/plugins/available/metadata/tabulate/)\n",
    "- [qiime taxa](https://docs.qiime2.org/2022.2/plugins/available/taxa/)\n",
    "- [qiime taxa barplot](https://docs.qiime2.org/2022.2/plugins/available/taxa/barplot/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T18:07:44.226852Z",
     "start_time": "2023-06-01T18:07:44.192451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from qiime2 import Artifact\n",
    "from qiime2 import Visualization\n",
    "from qiime2 import Metadata\n",
    "import qiime2.plugins.metadata.actions as metadata_actions\n",
    "from qiime2.plugins.metadata.visualizers import tabulate\n",
    "\n",
    "from qiime2.plugins import feature_classifier\n",
    "from qiime2.plugins import metadata\n",
    "from qiime2.plugins import taxa\n",
    "\n",
    "from qiime2.plugins.taxa.methods import collapse\n",
    "from qiime2.plugins.taxa.methods import filter_table\n",
    "from qiime2.plugins.feature_table.methods import filter_samples\n",
    "from qiime2.plugins.feature_table.methods import filter_seqs\n",
    "from qiime2.plugins.feature_table.visualizers import summarize\n",
    "from qiime2.plugins.feature_table.methods import relative_frequency\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from  statannot  import  add_stat_annotation\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:41.728605Z",
     "start_time": "2023-06-01T17:27:40.292982Z"
    }
   },
   "outputs": [],
   "source": [
    "# install scikit-learn specific version to use trained classifier\n",
    "%pip install --user 'scikit-learn==0.23.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving the parameters\n",
    "\n",
    "The following cell can receive parameters using the [papermill](https://papermill.readthedocs.io/en/latest/) tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:41.732605Z",
     "start_time": "2023-06-01T17:27:41.728605Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "metadata_file = '/home/lauro/nupeb/rede-micro/redemicro-miliane-nutri/data/raw/metadata/miliane-metadata-CxAC.tsv'\n",
    "base_dir = os.path.join('/', 'home', 'lauro', 'nupeb', 'rede-micro', 'redemicro-miliane-nutri')\n",
    "experiment_name = 'miliane-CxAC-trim'\n",
    "class_col = 'group-id'\n",
    "replace_files = False\n",
    "exclude_tax = False\n",
    "top_n = None\n",
    "classifier_file= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:41.906419Z",
     "start_time": "2023-06-01T17:27:41.867578Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_folder = os.path.abspath(os.path.join(base_dir, 'experiments', experiment_name))\n",
    "img_folder = os.path.abspath(os.path.join(experiment_folder, 'imgs'))\n",
    "sheet_folder = os.path.abspath(os.path.join(experiment_folder, 'sheets'))\n",
    "qiime_folder = os.path.join(experiment_folder, 'qiime-artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.093918Z",
     "start_time": "2023-06-01T17:27:41.904419Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p {img_folder}\n",
    "!mkdir -p {sheet_folder}\n",
    "!mkdir -p {qiime_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining names, paths and flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:45:29.669010Z",
     "start_time": "2023-06-01T17:45:29.618722Z"
    }
   },
   "outputs": [],
   "source": [
    "tax_level = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.098669Z",
     "start_time": "2023-06-01T17:27:42.092884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input - DADA2 Artifacts\n",
    "dada2_tabs_path = os.path.join(qiime_folder, 'dada2-tabs.qza')\n",
    "dada2_reps_path = os.path.join(qiime_folder, 'dada2-reps.qza')\n",
    "dada2_stat_path = os.path.join(qiime_folder, 'dada2-stat.qza')\n",
    "\n",
    "# Input - Taxonomy Classifier - SILVA 138-99\n",
    "classifier_path = classifier_file\n",
    "\n",
    "# Output - Excel file\n",
    "excel_path = os.path.join(sheet_folder, 'abundances.xlsx')\n",
    "\n",
    "# Output - Metataxonomy Artifact\n",
    "metatax_path = os.path.join(qiime_folder, 'metatax.qza')\n",
    "metatax_view_path = os.path.join(qiime_folder, 'metatax.qzv')\n",
    "metatax_bar_path = os.path.join(qiime_folder, 'metatax-bar.qzv')\n",
    "\n",
    "# Flag - Load or create files\n",
    "need_tax = not (os.path.isfile(metatax_path)) or replace_files\n",
    "need_view = not (os.path.isfile(metatax_view_path) and os.path.isfile(metatax_bar_path)) or replace_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step execution\n",
    "\n",
    "### Load input files\n",
    "\n",
    "This Step import the QIIME2 `SampleData[PairedEndSequencesWithQuality]` Artifact with all demultiplexed sequences and the `Metadata` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.125870Z",
     "start_time": "2023-06-01T17:27:42.098669Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_qa = Metadata.load(metadata_file)\n",
    "metadata_df = metadata_qa.to_dataframe()\n",
    "groups_values = list(metadata_qa.get_column(class_col).to_series().unique())\n",
    "# tabulate(metadata_qa).visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_tab_path = os.path.join(base_dir, 'data', 'interim', 'dada2-tabs.qza')\n",
    "# Verify if table file exists and if it is shared\n",
    "if not os.path.isfile(dada2_tabs_path) and os.path.isfile(alt_tab_path):\n",
    "    # If it is shared, create a local symbolic link\n",
    "    os.symlink(alt_tab_path, dada2_tabs_path)\n",
    "    \n",
    "alt_rep_path = os.path.join(base_dir, 'data', 'interim', 'dada2-reps.qza')\n",
    "# Verify if sequences file exists and if it is shared\n",
    "if not os.path.isfile(dada2_reps_path) and os.path.isfile(alt_rep_path):\n",
    "    # If it is shared, create a local symbolic link\n",
    "    os.symlink(alt_rep_path, dada2_reps_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FeatureData[Sequence] Artifact\n",
    "reps = Artifact.load(dada2_reps_path)\n",
    "\n",
    "# Load FeatureTable[Frequency] Artifact\n",
    "tabs = Artifact.load(dada2_tabs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter FeatureTable[Frequency | RelativeFrequency | PresenceAbsence | Composition] based on Metadata sample ID values\n",
    "tabs = filter_samples(\n",
    "    table=tabs,\n",
    "    metadata=metadata_qa,\n",
    ").filtered_table\n",
    "# Filter SampleData[SequencesWithQuality | PairedEndSequencesWithQuality | JoinedSequencesWithQuality] based on Metadata sample ID values; returns FeatureData[Sequence | AlignedSequence]\n",
    "reps = filter_seqs(\n",
    "    data=reps,\n",
    "    table=tabs,\n",
    ").filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.194014Z",
     "start_time": "2023-06-01T17:27:42.125870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asv_df = tabs.view(pd.DataFrame)\n",
    "\n",
    "if not need_tax:\n",
    "    \n",
    "    # Load FeatureData[Taxonomy]\n",
    "    metatax_qa = Artifact.load(metatax_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Load TaxonomicClassifier Artifact\n",
    "    classifier = Artifact.load(classifier_path)\n",
    "    \n",
    "    # Classify ASV features and create a new FeatureData[Taxonomy]\n",
    "    metatax_qa = feature_classifier.methods.classify_sklearn(reads=reps, classifier=classifier, n_jobs=threads).classification\n",
    "\n",
    "    # Save FeatureData[Taxonomy] Artifact\n",
    "    metatax_qa.save(metatax_path)\n",
    "\n",
    "metatax_df = metatax_qa.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.271628Z",
     "start_time": "2023-06-01T17:27:42.198013Z"
    }
   },
   "outputs": [],
   "source": [
    "if not need_view:\n",
    "    \n",
    "    # Load Metatax\n",
    "    metatax_qv = Visualization.load(metatax_view_path)\n",
    "    metatax_bar_qv = Visualization.load(metatax_bar_path)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Metataxonomy Table Visualization\n",
    "    metatax_qv = metadata.visualizers.tabulate(metatax_qa.view(Metadata))\n",
    "    metatax_qv.visualization.save(metatax_view_path)\n",
    "    \n",
    "    # Barplot Visualization\n",
    "    # Next, we can view the taxonomic composition of our samples with interactive bar plots. \n",
    "    # Generate those plots with the following command and then open the visualization.\n",
    "    metatax_bar_qv = taxa.visualizers.barplot(tabs, metatax_qa, metadata_qa)\n",
    "    metatax_bar_qv.visualization.save(metatax_bar_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metataxonomy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T22:05:30.118252Z",
     "start_time": "2023-06-01T22:05:30.074206Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_and_collapse(tab: Artifact, tax: Artifact, meta: Metadata, lvl: int, exclude: bool = True, exclude_list: str = 'uncultured,unidentified,metagenome,human') -> (Artifact, Visualization, pd.DataFrame):\n",
    "    \"\"\" Filter and collapse the taxonomy table to the desired level and exclude the exclude_list from the taxonomy table\n",
    "\n",
    "    :param tab: Artifact - qiime2 FeatureTable[Frequency] Artifact with the ASV table\n",
    "    :param tax: Artifact - qiime2 FeatureData[Taxonomy] Artifact with the taxonomy classification\n",
    "    :param meta: Metadata - qiime2 Metadata with the sample metadata\n",
    "    :param lvl: int - 1 to 7\n",
    "    :param exclude: bool - True to exclude the exclude_list from the taxonomy table\n",
    "    :param exclude_list: str - comma separated list of strings to exclude from the taxonomy table\n",
    "    :return: qiime2 FeatureTable[Frequency] Artifact, qiime2 Visualization, pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    to_include = ('d', 'p', 'c', 'o', 'f', 'g', 's')[lvl-1]\n",
    "    to_include += '__'\n",
    "    to_exclude = exclude_list if exclude else None\n",
    "    \n",
    "    if exclude:\n",
    "        filtered_tabs = filter_table(\n",
    "            table=tab, \n",
    "            taxonomy=tax,\n",
    "            include=to_include,\n",
    "            exclude=to_exclude,\n",
    "            mode='contains').filtered_table\n",
    "    else:\n",
    "        filtered_tabs = tab\n",
    "    \n",
    "    collapsed_table: Artifact = collapse(table=filtered_tabs, taxonomy=tax, level=lvl).collapsed_table\n",
    "    collapsed_table_view: Visualization = summarize(table=collapsed_table, sample_metadata=meta).visualization\n",
    "    collapsed_table_df: pd.DataFrame = collapsed_table.view(pd.DataFrame)\n",
    "    \n",
    "    return collapsed_table, collapsed_table_view, collapsed_table_df\n",
    "\n",
    "\n",
    "def get_keys_by_group(metadata_df: pd.DataFrame, asv_df: pd.DataFrame, group_id:str = 'group-id') -> dict:\n",
    "    \"\"\" Get a dictionary with group-id as key and a list of sample-id as value\n",
    "    Used to select samples from a group in an ASV dataframe\n",
    "    :param metadata_df: metadata dataframe from qiime2 Metadata Artifact\n",
    "    :param asv_df: ASV dataframe from qiime2 FeatureTable[Frequency] or FeatureTable[RelativeFrequency] Artifact\n",
    "    :return: dictionary with group-id as key and a list of sample-id as value\n",
    "    \"\"\"\n",
    "    groups_keys = dict()\n",
    "    for i in metadata_df.groupby(group_id):\n",
    "        groups_keys[i[0]] = asv_df.loc[i[1].index].index.tolist()\n",
    "    return groups_keys\n",
    "\n",
    "def expand_tax_cols(table_df: pd.DataFrame, metatax_df: pd.DataFrame, tax_col: str = 'Taxon') -> pd.DataFrame:\n",
    "    \"\"\" Split the taxonomy column in the FeatureData[Taxonomy] Artifact and join with the FeatureTable[Frequency] or FeatureTable[RelativeFrequency] Artifact\n",
    "     ASV table. Constructs a new dataframe with the abundance columns and the expanded taxonomy columns.\n",
    "\n",
    "    :param table_df: pandas DataFrame - ASV table from qiime2 FeatureTable[Frequency] or FeatureTable[RelativeFrequency] Artifact\n",
    "    :param metatax_df: pandas DataFrame - taxonomy dataframe from qiime2 FeatureData[Taxonomy] Artifact\n",
    "    :param tax_col: str - name of the taxonomy column in the metatax_df dataframe (default: 'Taxon')\n",
    "    :return: pandas DataFrame - new dataframe with the abundance columns and the expanded taxonomy columns\n",
    "    \"\"\"\n",
    "    tax_df = metatax_df[tax_col].str.split(';', expand=True)\n",
    "    new_df = table_df.T.join(metatax_df).join(tax_df)\n",
    "    return new_df\n",
    "\n",
    "def get_level_tax_df(table_df: pd.DataFrame, metatax_df: pd.DataFrame, level: int = 0, groups_keys: dict = None, round_by: int = 5, normalize: bool = False, filter_terms: list = None) -> pd.DataFrame:\n",
    "    \"\"\" Get a new dataframe with the abundance columns and the expanded taxonomy columns grouped by the level and normalized by the total sum of the level group (default: 0) or the total sum of the dataframe (normalize=False).\n",
    "\n",
    "    :param table_df: pandas DataFrame - ASV table from qiime2 FeatureTable[Frequency] or FeatureTable[RelativeFrequency] Artifact\n",
    "    :param metatax_df: pandas DataFrame - taxonomy dataframe from qiime2 FeatureData[Taxonomy] Artifact\n",
    "    :param level: int - 0 to 7 (default: 0)\n",
    "    :param groups_keys: dict - dictionary with group-id as key and a list of sample-id as value (default: None)\n",
    "    :param round_by: int - round the values by the number of decimals (default: 5)\n",
    "    :param normalize: bool - normalize the values between 0 and 1 (default: False)\n",
    "    :param filter_terms: list[str] - list of strings to filter the taxonomy dataframe (default: None)\n",
    "    :return: pandas DataFrame - new dataframe with the abundance columns and the expanded taxonomy columns grouped by the level and normalized by the total sum of the level group (default: 0) or the total sum of the dataframe (normalize=False)\n",
    "    \"\"\"\n",
    "\n",
    "    # expand the taxonomy columns and join the abundance columns from the ASV table (table_df) with the taxonomy table (metatax_df)\n",
    "    expanded_df = expand_tax_cols(table_df, metatax_df, tax_col='Taxon')\n",
    "    # fill the NaN values with '__unclassified'\n",
    "    expanded_df.fillna('__unclassified', inplace=True)\n",
    "    # group by the level and sum the abundance columns\n",
    "    grouped_freqs_df = expanded_df.groupby(by=level, axis=0).sum()\n",
    "    # remove the level prefix from the index strings\n",
    "    grouped_freqs_df.index = [x.split('__')[1] if len(x.split('__'))>1 else 'unclassified' for x in grouped_freqs_df.index]\n",
    "    # filter the dataframe by the filter_terms\n",
    "    if filter_terms is not None:\n",
    "        for tax in grouped_freqs_df.index:\n",
    "            if len([x for x in filter_terms if x in tax]) > 0:\n",
    "                grouped_freqs_df.drop(tax, axis=0, inplace=True)\n",
    "    # create a new dataframe\n",
    "    new_df = pd.DataFrame()\n",
    "    # sum the columns of the new dataframe to get the total sum of the level group\n",
    "    new_df['total_sum'] = grouped_freqs_df.sum(axis=1)\n",
    "    # verify if groups_keys is not empty\n",
    "    if groups_keys is not None:\n",
    "        # iterate over the groups_keys (k = group-id, v = list of sample-id)\n",
    "        for k, v in groups_keys.items():\n",
    "            # sum the columns of the group samples and add the group column to the new_df dataframe\n",
    "            new_df[f'{k}'] = grouped_freqs_df.loc[:, v].sum(axis=1)\n",
    "    # concatenate the new_df dataframe with the grouped_freqs_df dataframe along the columns.\n",
    "    new_df = pd.concat([new_df, grouped_freqs_df], axis=1)\n",
    "    # sort the dataframe by the total sum column. The most abundant taxa will be on top\n",
    "    new_df.sort_values(by='total_sum', ascending=False, inplace=True)\n",
    "    # normalize the new_df dataframe. To relate the abundance of each taxon to the total abundance of the dataframe\n",
    "    if normalize:\n",
    "        new_df = (new_df / new_df.sum()).round(round_by)\n",
    "    # return the dataframe\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.327159Z",
     "start_time": "2023-06-01T17:27:42.293596Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df(tab, col_name, exclude=True):\n",
    "    df = pd.DataFrame(tab.view(pd.DataFrame).sum(axis=0).sort_values(ascending=False), columns=[col_name])\n",
    "    if exclude:\n",
    "        new_index = [x.split(';')[-1][3:] for x in df.index]\n",
    "        df.index = new_index\n",
    "    return df\n",
    "\n",
    "def get_samples_df(tab, exclude=True):\n",
    "    df = tab.view(pd.DataFrame).T\n",
    "    if exclude:\n",
    "        new_index = [x.split(';')[-1][3:] for x in df.index]\n",
    "        df.index = new_index\n",
    "    return df\n",
    "\n",
    "def create_rank_df(table, meta, groups, exclude=True, gid='group-id'):\n",
    "    df = get_df(table, 'Total', exclude)\n",
    "    for g in groups:\n",
    "        query = f\"[{gid}]='{g}'\"\n",
    "        group = filter_samples(table=table, metadata=meta, where=query, exclude_ids=False).filtered_table\n",
    "        new_df = get_df(group, g, exclude)\n",
    "        df = df.join(new_df, )\n",
    "    df = df.fillna(0)\n",
    "    return df        \n",
    "\n",
    "def plot_rank(df, level_name, sort_by=None, top=None):\n",
    "    if level_name == 'Kingdom':\n",
    "        return\n",
    "    print_top = True if type(top) in [int] else False\n",
    "    print(sort_by)\n",
    "    plt.figure()\n",
    "    sns.set(rc={'figure.figsize':(12,4)})\n",
    "    df = df.drop(['Total'], axis=1)\n",
    "    if sort_by and sort_by in df.columns:\n",
    "        df = df.sort_values(by=sort_by, ascending=False)\n",
    "    if print_top:\n",
    "        df = df.head(top)\n",
    "    df.plot( kind='bar', stacked=True, )\n",
    "    plt.ylabel('Abundances')\n",
    "    plt.xlabel(level_name)\n",
    "    msg = 'x'.join(df.columns)\n",
    "    if print_top:\n",
    "        plt.title(f'Top {top} {level_name} abundances rank for groups {msg} - Sorted by {sort_by}')\n",
    "    else:\n",
    "        plt.title(f'{level_name} abundances rank for groups {msg} - Sorted by {sort_by}')\n",
    "    plt.tight_layout()\n",
    "    if print_top:\n",
    "        path = os.path.abspath(os.path.join(img_folder, f'abundance-rank-{level_name}-groups-{msg}-sorted-by-{sort_by}-top-{top}.svg'))\n",
    "    else:\n",
    "        path = os.path.abspath(os.path.join(img_folder, f'abundance-rank-{level_name}-groups-{msg}-sorted-by-{sort_by}.svg'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.376571Z",
     "start_time": "2023-06-01T17:27:42.328183Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_all_levels(tabs, metatax, metadata_qa, groups_values, experiment_name, to_exclude, gid='group-id', top=None):\n",
    "    level_names = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "    excel_name = f'abundance-ranks-{experiment_name}.xlsx'\n",
    "    excel_path = os.path.abspath(os.path.join(sheet_folder, excel_name))\n",
    "    with pd.ExcelWriter(excel_path, mode='w') as writer:\n",
    "        opts = (True, False) if to_exclude else (False, )\n",
    "        for exclude in opts:\n",
    "            for i, lvl_name in enumerate(level_names):\n",
    "                print(f'{i} - Processing {lvl_name} - Filtered {exclude}')\n",
    "\n",
    "                collapsed_table, collapsed_table_view, collapsed_table_df = filter_and_collapse(\n",
    "                    tabs, metatax, metadata_qa,\n",
    "                    lvl=i+1,\n",
    "                    exclude=exclude,\n",
    "                    exclude_list='uncultured,unidentified,metagenome,human')\n",
    "\n",
    "                rank_df = create_rank_df(collapsed_table, metadata_qa, groups=groups_values, exclude=exclude, gid=gid)\n",
    "                samples_df = get_samples_df(collapsed_table, exclude)\n",
    "                joined_df = rank_df.join(samples_df,)\n",
    "                sheet_name = f\"{lvl_name}{'-filtered' if exclude else ''}\"\n",
    "                joined_df.to_excel(writer, sheet_name=sheet_name)\n",
    "                if exclude:\n",
    "                    for g in ('total', *groups_values):\n",
    "                        msg = f\"{'Filtered-' if exclude else ''}{lvl_name}\"\n",
    "                        plot_rank(rank_df, level_name=lvl_name,sort_by=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.389263Z",
     "start_time": "2023-06-01T17:27:42.376571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def boxplot_rank(table, meta, tax, groups, lvl, exclude, gid='group-id', top=None):\n",
    "    level_names = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "    level_name = level_names[lvl-1]\n",
    "    print_top = True if type(top) in [int] else False\n",
    "    df = pd.DataFrame()\n",
    "    collapsed_table, _, _ = filter_and_collapse(\n",
    "        table, tax, meta, \n",
    "        lvl=lvl,\n",
    "        exclude=exclude, \n",
    "        exclude_list='uncultured,unidentified,metagenome,human')\n",
    "    collapsed_table_df = get_df(collapsed_table, col_name='Total')\n",
    "    ordered_tax = collapsed_table_df.index\n",
    "    for g in groups:\n",
    "        print(f'Processing {level_name} - {g}')\n",
    "        group = filter_samples(table=table, metadata=meta, where=f\"[{gid}]='{g}'\", exclude_ids=exclude).filtered_table\n",
    "        collapsed_group, _, _ = filter_and_collapse(\n",
    "            group, tax, meta, \n",
    "            lvl=lvl,\n",
    "            exclude=exclude, \n",
    "            exclude_list='uncultured,unidentified,metagenome,human')\n",
    "        collapsed_group_df = collapsed_group.view(pd.DataFrame)\n",
    "        new_cols = [x.split(';')[-1][3:] for x in collapsed_group_df.columns]\n",
    "        collapsed_group_df.columns = new_cols\n",
    "        cols = [x for x in ordered_tax if x in new_cols]\n",
    "        collapsed_group_df = collapsed_group_df[cols]\n",
    "        collapsed_group_df['Group'] = g\n",
    "        melted_df = collapsed_group_df.melt(value_name='Abundance', var_name='Taxonomy', id_vars='Group')\n",
    "        df = pd.concat([df, melted_df], axis=0)\n",
    "    # Select TOP N most abundant taxons\n",
    "    if print_top:\n",
    "        top_taxons = df.groupby('Taxonomy').sum().sort_values(by='Abundance', ascending=False).head(top_n).index.values.tolist()\n",
    "        df = df[df['Taxonomy'].isin(top_taxons)]\n",
    "    df['Abundance'] = np.log(df['Abundance']+1)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = sns.boxplot(x=df['Taxonomy'], y=df['Abundance'], hue=df['Group'])\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.set(ylabel='log(# of reads)')\n",
    "    if print_top:\n",
    "        plt.title(f'Top {top} {level_name} abundances rank by groups.')\n",
    "    else:\n",
    "        plt.title(f'{level_name} abundances rank by groups.')\n",
    "    plt.tight_layout()\n",
    "    if print_top:\n",
    "        path = os.path.abspath(os.path.join(img_folder, f'boxplot-abundance-rank-{level_name}-top-{top}.svg'))\n",
    "    else:\n",
    "        path = os.path.abspath(os.path.join(img_folder, f'boxplot-abundance-rank-{level_name}.svg'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:42.417586Z",
     "start_time": "2023-06-01T17:27:42.389263Z"
    }
   },
   "outputs": [],
   "source": [
    "# species = filter_table(\n",
    "#         table=tabs,\n",
    "#         taxonomy=metatax_qa,).filtered_table\n",
    "# species.view(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:27:52.362590Z",
     "start_time": "2023-06-01T17:27:42.430887Z"
    }
   },
   "outputs": [],
   "source": [
    "process_all_levels(tabs, metatax_qa, metadata_qa, groups_values, experiment_name, to_exclude=exclude_tax, gid=class_col, top=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T17:28:31.879473Z",
     "start_time": "2023-06-01T17:27:52.362590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    boxplot_rank(tabs, metadata_qa, metatax_qa, groups_values, lvl=i+1, exclude=exclude_tax, gid=class_col, top=top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Taxonomic abundance by groups - Make dataframes for each taxonomic level and save to file\n",
    "\n",
    "Create a dataframe with the taxonomic abundance by groups. The dataframe will have one column for the total abundance on a taxonomic level one for each group and one for each sample. The rows will be the taxons on the taxonomic level. There will be one sheet for each taxonomic level, for each frequency type (relative and absolute).\n",
    "\n",
    "There are seven taxonomic levels: Kingdom, Phylum, Class, Order, Family, Genus and Species.\n",
    "\n",
    "Example sheets:\n",
    "- With absolute frequencies: [link to Google Drive](https://docs.google.com/spreadsheets/d/12vnaEZyOZXDbVBKXQBpEMLW1Y1-bZp1i/edit?usp=sharing&ouid=109330023391628055946&rtpof=true&sd=true)\n",
    "- With relative frequencies: [link to Google Drive](https://docs.google.com/spreadsheets/d/1WiU2atDOz9rbCFsd3BOzUj3yK59O4b-j/edit?usp=sharing&ouid=109330023391628055946&rtpof=true&sd=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T22:05:33.667476Z",
     "start_time": "2023-06-01T22:05:32.661472Z"
    }
   },
   "outputs": [],
   "source": [
    "# get groups sample-id keys from metadata and asv tables\n",
    "groups_keys = get_keys_by_group(metadata_df=metadata_df, asv_df=asv_df,group_id=class_col)\n",
    "print(f'Groups keys: {groups_keys}')\n",
    "\n",
    "to_filter_terms = None\n",
    "to_filter_terms = ['uncultured', 'unidentified', 'metagenome', 'human']\n",
    "\n",
    "\n",
    "# define if the frequencies will be persisted\n",
    "persist = True\n",
    "\n",
    "frequency_tables = {'relative-filtered': None, 'absolute-filtered': None, 'relative-all': None, 'absolute-all': None}\n",
    "\n",
    "# iterate over frequencies types\n",
    "for tax_tables in frequency_tables.keys():\n",
    "    print(f'Processing {tax_tables} frequencies')\n",
    "    # define if frequencies are relative or absolute\n",
    "    is_relative = True if tax_tables.split('-')[0] == 'relative' else False\n",
    "    # create a list to store level sheets\n",
    "    level_sheets = list()\n",
    "    # iterate over taxonomic levels\n",
    "    for lvl in range(7):\n",
    "        print(f'Processing level {lvl} for {tax_tables} frequencies')\n",
    "        filter_terms = to_filter_terms if tax_tables.split('-')[1] == 'filtered' else None\n",
    "        # get taxonomic level dataframe\n",
    "        level_df = get_level_tax_df(table_df=asv_df, metatax_df=metatax_df, level=lvl, groups_keys=groups_keys, round_by=5, normalize=is_relative, filter_terms=filter_terms)\n",
    "        # append to level sheets\n",
    "        level_sheets.append(level_df)\n",
    "\n",
    "    # store frequencies by frequency type\n",
    "    frequency_tables[tax_tables] = level_sheets\n",
    "\n",
    "    # persist frequencies to xlsx\n",
    "    if persist:\n",
    "        print(f'Persisting {tax_tables} frequencies to xlsx')\n",
    "        # define xlsx path\n",
    "        xlsx_path = os.path.join(sheet_folder, f'{tax_tables}_frequencies.xlsx')\n",
    "        print(f'Xlsx path: {xlsx_path}')\n",
    "        # create ExcelWriter object to write to xlsx file\n",
    "        with pd.ExcelWriter(xlsx_path) as writer:\n",
    "            # iterate over level sheets\n",
    "            for i, lvl_df in enumerate(level_sheets):\n",
    "                #df = (lvl*100).round(5)\n",
    "                lvl_df.to_excel(writer, sheet_name=f'{tax_level[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Taxonomic abundance by groups - Barplots with statistical significance\n",
    "\n",
    "We create boxplot with the abundance of the top N most abundant taxonomy on each taxonomic level. The boxplot will be grouped by groups and will have the abundance on the y-axis and the taxonomies on the x-axis. There will be one boxplot for each taxonomic level, for each frequency type (relative and absolute).\n",
    "\n",
    "There are seven taxonomic levels: Kingdom, Phylum, Class, Order, Family, Genus and Species.\n",
    "\n",
    "Example boxplot:\n",
    "- [boxplot-absolute-all-abundance-Species-top-10.svg](https://drive.google.com/file/d/12Y7I5i4Dalk7nwh4cu-t_4C4SIwL1VTS/view?usp=sharing)\n",
    "- [boxplot-absolute-filtered-abundance-Species-top-10.svg](https://drive.google.com/file/d/1QZMdvA8gW5j0l5uBvPJtX5kmHr4Uier0/view?usp=sharing)\n",
    "- [boxplot-relative-all-abundance-Species-top-10.svg](https://drive.google.com/file/d/1n0CT7Cgj-1BYjcS7uhDH6sXTn7PFoL5V/view?usp=sharing)\n",
    "- [boxplot-relative-filtered-abundance-Species-top-10.svg](https://drive.google.com/file/d/1qqdAu6STaDo7prxlmQSGdQ88dWq1BUWT/view?usp=sharing)\n",
    "\n",
    "**p-value** annotation legend:\n",
    "ns: 0.05 < p <= 1.00\n",
    "*: 0.01 < p <= 0.05\n",
    "**: 0.001 < p <= 0.01\n",
    "***: 0.0001 < p <= 0.001\n",
    "****: p <= 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T22:18:56.597575Z",
     "start_time": "2023-06-01T22:18:24.357700Z"
    }
   },
   "outputs": [],
   "source": [
    "# DEFINE VARS\n",
    "if top_n is None:\n",
    "    top_n = 10\n",
    "group_label = 'Grupo'\n",
    "do_plot = True\n",
    "n_groups = len(groups_keys.keys())\n",
    "\n",
    "# ITERATE OVER FREQUENCIES (RELATIVE AND ABSOLUTE)\n",
    "for tab_idx, levels_list in frequency_tables.items():\n",
    "    # ITERATE OVER ALL TAX LEVELS (KINGDOM, PHYLUM, CLASS, ORDER, FAMILY, GENUS, SPECIES)\n",
    "    for lvl, level_name in enumerate(tax_level):\n",
    "        # SELECT LEVEL DATAFRAME\n",
    "        df = levels_list[lvl].iloc[:top_n, (n_groups+1):].T\n",
    "        # CREATE GROUPED MELTED DF\n",
    "        df[group_label] = 'NaN'\n",
    "        for k, v in groups_keys.items():\n",
    "            df.loc[v, group_label] = k\n",
    "        df = df.melt(value_name='Abundance', var_name='Taxonomy', id_vars=group_label)\n",
    "\n",
    "        if do_plot:\n",
    "\n",
    "            # CREATE BOXPLOT STATS PAIRS\n",
    "            box_pairs = list()\n",
    "            taxons = df['Taxonomy'].unique()\n",
    "            groups = df[group_label].unique()\n",
    "            for t in taxons:\n",
    "                tax_rows = list()\n",
    "                for j in range(0, len(groups)):\n",
    "                    for jj in range(j+1, len(groups)):\n",
    "                        row = ((t, groups[j]), (t, groups[jj]))\n",
    "                        tax_rows.append(row)\n",
    "                box_pairs.extend(tax_rows)\n",
    "\n",
    "            # PLOT BOXPLOTS\n",
    "            plt.figure(figsize=(21,9), dpi=100)\n",
    "            ax = sns.boxplot(x=df['Taxonomy'], y=df['Abundance'], hue=df[group_label])\n",
    "            ax, test_results = add_stat_annotation(ax, data=df, x=df['Taxonomy'], y=df['Abundance'],\n",
    "                                                   hue=df[group_label],\n",
    "                                                   box_pairs=box_pairs,\n",
    "                                                   test='Mann-Whitney',\n",
    "                                                   loc='inside', verbose=2, #text_format='star',\n",
    "                                                   )\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "            ax.set(ylabel=f'{tab_idx.split(\"-\")[0]} frequency')\n",
    "            plt.title(f'{f\"Top {top_n} \" if top_n is not None else \"\"}{level_name} {tab_idx} abundances rank by groups.')\n",
    "            plt.tight_layout()\n",
    "            sns.despine()\n",
    "\n",
    "            # SAVE FIGURE\n",
    "            path = os.path.abspath(os.path.join(img_folder, f'boxplot-{tab_idx}-abundance-{level_name}{f\"-top-{top_n}\" if top_n is not None else \"\"}.svg'))\n",
    "            print(f'Saving boxplot with statistical significance to {path} - using {tab_idx} frequencies')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path, format='svg')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
